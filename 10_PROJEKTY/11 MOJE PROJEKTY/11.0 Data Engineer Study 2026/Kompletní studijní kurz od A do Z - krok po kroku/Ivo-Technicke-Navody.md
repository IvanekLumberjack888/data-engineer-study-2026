# ğŸ¯ KONKRÃ‰TNÃ TECHNICKÃ‰ NÃVODY

## 1ï¸âƒ£ OBSIDIAN SETUP (5 minut)

### Krok 1: VytvoÅ™ Vault

```bash
# V Obsidian: File â†’ Create new vault
# JmÃ©no: Data Engineer Study 2026
# UmÃ­stÄ›nÃ­: ~/Projects/Data Engineer Study 2026
```

### Krok 2: VytvoÅ™ sloÅ¾ky

```bash
mkdir -p "Data Engineer Study 2026"/{Daily,Learn,Projects,Templates}
```

### Krok 3: Plugins - Install jen TYTO 4

```
Obsidian â†’ Settings â†’ Community Plugins

1. Daily Notes
   - Settings: Daily notes folder: "Daily"
   - Template: "Templates/Daily Note.md"

2. Templater
   - Enable: "Trigger Templater on file creation"

3. Dataview
   - (Default nastavenÃ­ je fine)

4. (Optional) Smart Connections
```

### Krok 4: VytvoÅ™ Templates

**Soubor: Templates/Daily Note.md**
```markdown
---
date: 2025-11-03
week: 0
---

# Daily Note - pondÄ›lÃ­, listopadu 3.

## DneÅ¡nÃ­ plÃ¡n
- [ ] Task 1
- [ ] Task 2
- [ ] Task 3

## Co jsem se nauÄil
-

## GitHub commitÅ¯
-

## XP dnes
- Daily: 5 XP
- Tasks: ___ XP
- Projects: ___ XP

## Next day
-

---

## PropojenÃ© poznÃ¡mky
- [[Learn/Python]]
- [[Projects/Project-1]]
- [[Progress]]
```

**Soubor: Templates/Project.md**
```markdown
---
tag: #project
status: ğŸ”´ not-started
started: 2025-11-03
---

# Projekt: Ivo-Technicke-Navody

## CÃ­l
JednovÄ›tÃ­ popis co projekt dÄ›lÃ¡

## Tech Stack
- Python
- GCP/BigQuery
- Airflow
- dbt

## FÃ¡ze
- [ ] FÃ¡ze 1: Setup
- [ ] FÃ¡ze 2: Development
- [ ] FÃ¡ze 3: Testing
- [ ] FÃ¡ze 4: Documentation

## GitHub Link
[Repository](https://github.com/ivodolezal/project-xyz)

## Learning outcomes
- [[SQL]]
- [[Python]]
- [[Airflow]]

## Status
ğŸŸ¡ IN PROGRESS

## Deadline
```

---

## 2ï¸âƒ£ GITHUB REPO SETUP (10 minut)

### Struktura

```bash
cd ~/Projects
git clone https://github.com/ivodolezal/data-engineer-study-2026.git
cd data-engineer-study-2026

# VytvoÅ™ tuhle strukturu:
mkdir -p {weeks,projects,scripts,docs}

# weeks/: week-01.md aÅ¾ week-23.md
# projects/: 1-etl-local, 2-cloud-pipeline, 3-realtime-rag
# scripts/: generate_dashboard.py, weekly_xp.py, track_progress.py
# docs/: learning-notes.md, architectures.md, interview-prep.md

# VytvoÅ™ README.md (obsah nÃ­Å¾e)
# First commit!
```

### README.md Template

```markdown
# Data Engineer Study 2026 ğŸš€

Personal learning journey: **1. listopadu 2025 â†’ 31. bÅ™ezna 2026**

**CÃ­l**: Junior/Medior Data Engineer v BrnÄ› (50-70k CZK)

---

## ğŸ“Š Progress Dashboard

| Metrika | Status |
|---------|--------|
| TÃ½dny | 0/23 |
| XP Total | 0/2300 |
| GitHub Commits | 0 |
| Portfolio Projekty | 0/3 |
| LinkedIn Followers | 0 |

---

## ğŸ“š Learning Path

### FÃ¡ze 1: Fundamenty (TÃ½dny 1-8)
- [x] Python refresh
- [x] SQL mastery
- [ ] Project 1: Local ETL

### FÃ¡ze 2: Cloud (TÃ½dny 9-16)
- [ ] GCP BigQuery
- [ ] Apache Airflow
- [ ] dbt Core
- [ ] Project 2: Cloud Pipeline

### FÃ¡ze 3: Advanced (TÃ½dny 17-23)
- [ ] Spark Streaming
- [ ] ML + Comet
- [ ] RAG + Perplexity API
- [ ] Project 3: Real-time RAG

---

## ğŸ¯ Portfolio Projekty

### Project 1: Local ETL Pipeline
- Stack: Python, DuckDB, Pandas
- Link: [projects/1-etl-local](projects/1-etl-local)
- Status: â³ Not started

### Project 2: Cloud Data Pipeline
- Stack: GCP, BigQuery, Airflow, dbt, Metabase
- Link: [projects/2-cloud-pipeline](projects/2-cloud-pipeline)
- Status: â³ Not started

### Project 3: Real-time RAG System
- Stack: Kafka, Spark, BigQuery, LangChain, Perplexity API
- Link: [projects/3-realtime-rag](projects/3-realtime-rag)
- Status: â³ Not started

---

## ğŸ”— UÅ¾iteÄnÃ© Zdroje

### Kurzy (ZDARMA)
- [Data with Baraa - SQL](https://youtube.com/@DataWithBaraa)
- [freeCodeCamp - Data Engineering](https://freecodecamp.org)
- [Dagster - Data Engineering Intro](https://dagster.io/learn)
- [dbt Learn](https://learn.getdbt.com)

### Tools
- [GCP Free Tier](https://cloud.google.com/free)
- [BigQuery Sandbox](https://cloud.google.com/bigquery/docs/sandbox)
- [Apache Airflow](https://airflow.apache.org/)
- [dbt Core](https://www.getdbt.com/)
- [Metabase](https://www.metabase.com/)

### Dokumentace
- [Week 01-23 Notes](weeks/)
- [Learning Notes](docs/learning-notes.md)
- [Architecture Decisions](docs/architectures.md)
- [Interview Prep](docs/interview-prep.md)

---

## ğŸ“ˆ Weekly XP Progress

Week 1: â³ In progress...

---

## ğŸ“ Contact & Social

- **LinkedIn**: [ivodolezal](https://linkedin.com/in/ivodolezal)
- **GitHub**: [@ivodolezal](https://github.com/ivodolezal)
- **Email**: ivo@example.com

---

*Last Updated: 1. listopadu 2025*
```

---

## 3ï¸âƒ£ PERPLEXITY PRO WORKFLOW (KaÅ¾dÃ½ den)

### StandardnÃ­ otÃ¡zky ke studiu

```python
# daily_perplexity_prompts.txt

PONDÄšLÃ - Research:
"VysvÄ›tli mi Apache Airflow a jak funkÄÃ­ DAG scheduling. 
 Dej mi praktickÃ½ pÅ™Ã­klad s Python kodem."

ÃšTERÃ - Deep Dive:
"JakÃ½ je rozdÃ­l mezi ETL a ELT? 
 KdyÅ¾ bych chtÄ›l vytvoÅ™it data pipeline v GCP, kterou bych mÄ›l zvolit?"

STÅ˜EDA - Problem Solving:
"Tady je mÅ¯j Python script [PASTE]. ProÄ mi seluje s tÃ­mhle error? 
 Jak ho mÃ¡m opravit?"

ÄŒTVRTEK - Architecture:
"Navrhni mi end-to-end data architecture pro real-time analytics. 
 Co vÅ¡echno potÅ™ebuji a v jakÃ© sekvenci?"

PÃTEK - Reflection:
"Sumarizuj mi to, co jsem se nauÄil tento tÃ½den o data engineering."

SOBOTA - Project Planning:
"PodÃ­vej se na tuhle GitHub issue [LINK]. Jak bych mÄ›l Å™eÅ¡it tahle Ãºkol?"
```

### Jak to zapisovat do Obsianu

```markdown
# Daily Note - 2025-11-04

## Perplexity Insights
Dnes jsem se ptÃ¡l na "Apache Airflow basics"

### KlÃ­ÄovÃ© body
- DAG = Directed Acyclic Graph
- Task scheduling: cron-based
- Backfill moÅ¾nost = super pro historical data

### Code snippet (od Perplexity)
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def my_task():
    print("Hello from Airflow!")

with DAG('my_dag', start_date=datetime(2025, 1, 1)) as dag:
    task1 = PythonOperator(task_id='task1', python_callable=my_task)
```

### PropojenÃ­
- [[Learn/Airflow]] â† linked concept
- [[Projects/Project-2]] â† pouÅ¾Ã­vÃ¡m v projektu
```

---

## 4ï¸âƒ£ COMET ML INTEGRACE

### Setup

```bash
# Install
pip install comet-ml

# Get API key z https://www.comet.com
export COMET_API_KEY="your-api-key-here"
```

### MinimÃ¡lnÃ­ Python kÃ³d

```python
from comet_ml import Experiment

# Start experiment
experiment = Experiment(
    api_key="your-api-key",
    project_name="data-engineering-study",
    workspace="ivodolezal"
)

# Log nÄ›co
experiment.log_parameters({"model": "simple_etl", "version": "v1"})
experiment.log_metrics({"quality_score": 0.92})

# Finished
experiment.end()

# ZkopÃ­ruj URL do Obsianu!
print(f"Experiment URL: {experiment.url}")
```

---

## 5ï¸âƒ£ GITHUB ACTIONS - AUTO-PROGRESS

### Soubor: .github/workflows/study-progress.yml

```yaml
name: Weekly Study Progress

on:
  schedule:
    - cron: '0 20 * * 0'  # KaÅ¾dou nedÄ›li v 20:00
  workflow_dispatch:

jobs:
  update-progress:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          pip install -r scripts/requirements.txt
      
      - name: Generate dashboard
        run: |
          python scripts/generate_dashboard.py
      
      - name: Commit and push
        run: |
          git config --local user.email "ivo@example.com"
          git config --local user.name "Ivo"
          git add README.md docs/progress.md
          git commit -m "ğŸ“Š Weekly progress update - $(date +%Y-W%V)"
          git push
```

### Soubor: scripts/generate_dashboard.py

```python
#!/usr/bin/env python3
import subprocess
import json
from datetime import datetime

def count_commits():
    result = subprocess.run(['git', 'rev-list', '--count', 'HEAD'], 
                          capture_output=True, text=True)
    return int(result.stdout.strip())

def get_weekly_stats():
    commits = count_commits()
    xp = commits * 5  # Simple: 5 XP per commit
    
    return {
        "week": datetime.now().isocalendar()[1],
        "commits": commits,
        "xp": xp,
        "timestamp": datetime.now().isoformat()
    }

def update_readme():
    stats = get_weekly_stats()
    
    progress_line = f"""
| TÃ½dny | {stats['week']}/23 |
| GitHub Commits | {stats['commits']} |
| XP Total | {stats['xp']} |
"""
    
    # NahraÄ v README.md
    with open('README.md', 'r') as f:
        content = f.read()
    
    # (JednoduchÃ¡ nÃ¡hrada - v produkci bys to dÄ›lal lÃ©pe)
    with open('README.md', 'w') as f:
        f.write(content)  # ZapÃ­Å¡eÅ¡ novÃ© ÄÃ­sla
    
    print(f"âœ… Dashboard updated: {stats['commits']} commits, {stats['xp']} XP")

if __name__ == '__main__':
    update_readme()
```

---

## 6ï¸âƒ£ KONKRÃ‰TNÃ PÅ˜ÃKAZY NA DENNÃ BÃZI

### RannÃ­ rituÃ¡l (v BASH/ZSH)

```bash
#!/bin/bash
# daily_ritual.sh - SpusÅ¥ rÃ¡no v 17:05

cd ~/Projects/data-engineer-study-2026

# 1. Pull latest changes
git pull

# 2. Create/open today's daily note in Obsidian
DAILY_FILE="Daily/$(date +%Y-%m-%d).md"
if [ ! -f "$DAILY_FILE" ]; then
    cp Templates/Daily\ Note.md "$DAILY_FILE"
    echo "âœ… Daily note created"
fi

# 3. Open VS Code
code .

# 4. Open Perplexity Pro
open "https://www.perplexity.com"

# 5. Start Toggl (if using)
open "https://track.toggl.com"

echo "ğŸš€ Startup complete! Let's code!"
```

### VeÄernÃ­ wrap-up (v BASH/ZSH)

```bash
#!/bin/bash
# evening_wrap.sh - SpusÅ¥ veÄer v 18:00

cd ~/Projects/data-engineer-study-2026

# 1. Auto-commit today's progress
git add -A
git commit -m "ğŸ“ Day $(date +%d) progress: learnings + coding session"

# 2. Update daily note s finÃ¡lnÃ­m statusem
echo -e "\n## DONE âœ…\n$(date)\n" >> "Daily/$(date +%Y-%m-%d).md"

# 3. Push to GitHub
git push

# 4. Show stats
git log --oneline -10

echo "âœ… Session wrapped! See you tomorrow!"
```

### TÃ½dennÃ­ review (v BASH/ZSH)

```bash
#!/bin/bash
# weekly_review.sh - SpusÅ¥ v pÃ¡tek/sobotu

cd ~/Projects/data-engineer-study-2026

echo "ğŸ“Š WEEKLY REVIEW"
echo "=============="

# Count commits
COMMITS=$(git rev-list --count HEAD)
echo "Total commits: $COMMITS"

# Simple XP calc
XP=$((COMMITS * 5))
echo "XP earned this week: $XP"

# List what we learned
echo -e "\nğŸ“š Main learnings this week:"
grep -r "Co jsem se nauÄil" Daily/*.md | tail -7

# Open Obsidian weekly note
WEEK_NUM=$(date +%U)
open "obsidian://open?vault=Data%20Engineer%20Study%202026&file=weeks%2Fweek-$(printf "%02d" $WEEK_NUM).md"

echo -e "\nâœ… Review complete! Claim your reward:"
if [ $XP -ge 100 ]; then
    echo "ğŸ¥‡ GOLD: Pizza time! ğŸ•"
elif [ $XP -ge 80 ]; then
    echo "ğŸ¥ˆ SILVER: 2h gaming ğŸ®"
else
    echo "ğŸ¥‰ BRONZE: DobrÃ¡ kÃ¡va â˜•"
fi
```

---

## âœ… CHECKLIST: PRVNÃCH 24 HODIN

- [ ] (5 min) VytvoÅ™ GitHub repo "data-engineer-study-2026"
- [ ] (30 min) Obsidian vault setup + plugins
- [ ] (15 min) VytvoÅ™ prvnÃ­ Daily note
- [ ] (10 min) Perplexity Pro: Otestuj si 2 dotazy
- [ ] (20 min) Nainstaluj Comet ML
- [ ] (10 min) First GitHub commit: "ğŸš€ Initial setup"

**DONE!** TeÄ mÅ¯Å¾eÅ¡ zaÄÃ­t se studiem.

---

## ğŸ“± VÄšCI K NEMÄšNÄšNÃ

```
âŒ NEMÄšÅ‡UJ PLÃN kaÅ¾dÃ½ tÃ½den
   â†’ Review only na konci mÄ›sÃ­ce

âŒ NEPÅ˜IDÃVEJ novÃ© nÃ¡stroje
   â†’ MÃ¡Å¡ vÅ¡e co potÅ™ebujeÅ¡

âŒ NEPRACUJ 10h dennÄ›
   â†’ 1-2h dennÄ› je lepÅ¡Ã­ neÅ¾ burnout

âŒ NEREVIDUJ kÃ³d na perfekci
   â†’ "Done is better than perfect"

âœ… RÃDÄš MÅ®Å½EÅ 
   â†’ ZmenÅ¡it cÃ­le pokud je to moc
   â†’ Pivotovat pokud najdeÅ¡ lepÅ¡Ã­ cestu
   â†’ PÅ™idat poznÃ¡mky do Obsianu
```

---

## ğŸ¯ FINÃLNÃ REMINDER

**Nech to bÄ›Å¾et.**

NejdÅ¯leÅ¾itÄ›jÅ¡Ã­ je **konzistenci**, ne dokonalost.

**1 commit dennÄ› = 330 commitÅ¯ za 23 tÃ½dnÅ¯ = amazing portfolio**

**Let's go! ğŸš€**
